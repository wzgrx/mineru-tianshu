"""
RTX 5090 Benchmark Tool for Tianshu
æµ‹è¯• PaddleOCR å’Œ MinerU åœ¨å½“å‰ç¯å¢ƒä¸‹çš„ååé‡
"""
import time
import torch
import paddle
from loguru import logger

def benchmark_pytorch():
    logger.info("ğŸ”¥ Benchmarking PyTorch (CUDA)...")
    if not torch.cuda.is_available():
        logger.error("âŒ CUDA not available!")
        return
    
    device = torch.device("cuda")
    logger.info(f"   GPU: {torch.cuda.get_device_name(0)}")
    
    # ç®€å•çš„çŸ©é˜µä¹˜æ³•å‹åŠ›æµ‹è¯•
    size = 10000
    a = torch.randn(size, size, device=device, dtype=torch.float16)
    b = torch.randn(size, size, device=device, dtype=torch.float16)
    
    # é¢„çƒ­
    for _ in range(5): torch.mm(a, b)
    torch.cuda.synchronize()
    
    start = time.time()
    for _ in range(10):
        torch.mm(a, b)
    torch.cuda.synchronize()
    end = time.time()
    
    logger.info(f"   âœ… Matrix Mul (10k x 10k, FP16): {(end - start)/10:.4f} seconds/iter")

def benchmark_paddle():
    logger.info("ğŸ”¥ Benchmarking PaddlePaddle...")
    if not paddle.device.is_compiled_with_cuda():
        logger.error("âŒ Paddle CUDA not compiled!")
        return

    paddle.set_device("gpu:0")
    # ç®€å•çš„ Paddle æµ‹è¯•é€»è¾‘...
    logger.info("   âœ… Paddle GPU initialized successfully.")

if __name__ == "__main__":
    benchmark_pytorch()
    benchmark_paddle()
