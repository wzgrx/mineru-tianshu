"""
PaddleOCR ç»Ÿä¸€è§£æžå¼•æ“Ž (æœ€ç»ˆä¿®å¤ç‰ˆ - é€‚é… PaddleOCR 3.0+)
æ”¯æŒæ¨¡åž‹:
1. PaddleOCR-VL (v1 / v1.5) - å¤šæ¨¡æ€æ–‡æ¡£ç†è§£
2. PP-OCRv5 - é«˜ç²¾åº¦çº¯æ–‡æœ¬è¯†åˆ« (æ”¯æŒ 109 ç§è¯­è¨€)
3. PP-StructureV3 - ç‰ˆé¢åˆ†æžä¸Žè¡¨æ ¼è¿˜åŽŸ (ä½¿ç”¨æ–°ç‰ˆ API)
4. PP-ChatOCRv4 - æ™ºèƒ½ä¿¡æ¯æå– (åŸºç¡€è§†è§‰æ¨¡å¼)
"""
import os
import json
from pathlib import Path
from typing import Optional, Dict, Any
from threading import Lock
from loguru import logger
import numpy as np

# å°è¯•å¯¼å…¥å¿…è¦çš„åº“
try:
    import paddle
    # åŸºç¡€ OCR
    from paddleocr import PaddleOCR
    
    # å°è¯•å¯¼å…¥ 3.x æ–°å¢ž/æ›´æ–°çš„ç±»
    try:
        from paddleocr import PaddleOCRVL
    except ImportError:
        PaddleOCRVL = None
        logger.warning("âš ï¸ PaddleOCRVL not found. Please upgrade paddleocr>=2.9.1")

    try:
        from paddleocr import PPStructureV3
    except ImportError:
        PPStructureV3 = None
        # å°è¯•ä½¿ç”¨æ—§ç‰ˆå…¼å®¹
        from paddleocr import PPStructure
        logger.warning("âš ï¸ PPStructureV3 class not found, using PPStructure compatibility mode.")

    try:
        from paddleocr import PPChatOCRv4Doc
    except ImportError:
        PPChatOCRv4Doc = None
        
    import fitz # PyMuPDF, ç”¨äºŽ PDF è½¬å›¾ç‰‡
except ImportError as e:
    logger.error(f"âŒ Missing dependencies: {e}. Please run: pip install 'paddleocr>=2.9.1' pymupdf")
    raise

class PaddleOCREngine:
    """
    PaddleOCR å¼•æ“Žç®¡ç†å™¨ - å•ä¾‹æ¨¡å¼
    """
    _instance: Optional["PaddleOCREngine"] = None
    _lock = Lock()
    _models = {} 

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, device: str = "cuda:0"):
        if hasattr(self, "_initialized") and self._initialized: return
        
        with self._lock:
            if hasattr(self, "_initialized") and self._initialized: return
            
            self.device = device
            self.use_gpu = "cuda" in str(device).lower()
            if self.use_gpu:
                try:
                    self.gpu_id = int(str(device).split(":")[-1])
                except: self.gpu_id = 0
            else: self.gpu_id = 0
            
            self._init_env()
            self._initialized = True
            logger.info(f"ðŸ”§ PaddleOCR Engine initialized (Device: {device}, GPU: {self.use_gpu})")

    def _init_env(self):
        try:
            if self.use_gpu:
                if not paddle.device.is_compiled_with_cuda():
                    logger.warning("âš ï¸ PaddlePaddle CUDA not found! Falling back to CPU.")
                    self.use_gpu = False
                else:
                    paddle.set_device(f"gpu:{self.gpu_id}")
            else:
                paddle.set_device("cpu")
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to set paddle device: {e}")

    def _get_model(self, model_type: str, lang: str = 'ch'):
        """æ ¹æ®ç±»åž‹å’Œè¯­è¨€æ‡’åŠ è½½æ¨¡åž‹å®žä¾‹"""
        # ç¼“å­˜é”®
        cache_key = f"{model_type}_{lang}"
        if cache_key in self._models: return self._models[cache_key]

        with self._lock:
            if cache_key in self._models: return self._models[cache_key]
            logger.info(f"ðŸ“¥ Loading PaddleOCR model: {model_type} (Lang: {lang})...")
            
            instance = None
            try:
                # =========================================================
                # 1. PaddleOCR-VL ç³»åˆ— (v1 / v1.5)
                # =========================================================
                if 'paddleocr-vl' in model_type and 'vllm' not in model_type:
                    if PaddleOCRVL is None:
                        raise ImportError("PaddleOCRVL not available. Check paddleocr version.")
                    
                    # ç‰ˆæœ¬åˆ¤æ–­
                    ver = 'v1.5' # é»˜è®¤æœ€æ–°
                    if '0.9b' in model_type and '1.5' not in model_type:
                        ver = 'v1'
                    
                    logger.info(f"   ðŸš€ Mode: PaddleOCR-VL (Version: {ver})")
                    
                    # ã€ä¿®å¤ã€‘ç§»é™¤ä¸æ”¯æŒçš„ models_dir å‚æ•°ï¼Œä»…ä½¿ç”¨å®˜æ–¹æ”¯æŒçš„å‚æ•°
                    instance = PaddleOCRVL(
                        pipeline_version=ver,
                        use_doc_orientation_classify=True,
                        use_doc_unwarping=True,
                        use_layout_detection=True
                    )

                # =========================================================
                # 2. PP-StructureV3 (ç‰ˆé¢åˆ†æž)
                # =========================================================
                elif 'pp-structure' in model_type:
                    logger.info("   ðŸ—ï¸ Mode: PP-StructureV3")
                    if PPStructureV3:
                        instance = PPStructureV3(
                            use_doc_orientation_classify=True,
                            use_doc_unwarping=True,
                            use_gpu=self.use_gpu,
                            lang='ch' if lang=='auto' else lang
                        )
                    else:
                        # é™çº§å…¼å®¹æ—§ç‰ˆ
                        from paddleocr import PPStructure
                        instance = PPStructure(
                            show_log=False,
                            image_orientation=True,
                            structure_version='PP-StructureV3',
                            use_gpu=self.use_gpu,
                            lang='ch' if lang=='auto' else lang
                        )

                # =========================================================
                # 3. PP-ChatOCRv4 (æ™ºèƒ½æå–)
                # =========================================================
                elif 'pp-chatocr' in model_type:
                    logger.info("   ðŸ’¬ Mode: PP-ChatOCRv4")
                    if PPChatOCRv4Doc:
                        # ChatOCR åŸºç¡€åˆå§‹åŒ–ï¼ŒVisual Predict ä¸éœ€è¦ key
                        instance = PPChatOCRv4Doc(
                            use_doc_orientation_classify=True,
                            use_doc_unwarping=True
                        )
                    else:
                        logger.warning("âš ï¸ PPChatOCRv4Doc not found. Falling back to PP-Structure.")
                        from paddleocr import PPStructure
                        instance = PPStructure(structure_version='PP-StructureV3')

                # =========================================================
                # 4. PP-OCRv5 (é€šç”¨ OCR)
                # =========================================================
                else: 
                    logger.info("   âš¡ Mode: PP-OCRv5")
                    # PaddleOCR 3.x ä¼šè‡ªåŠ¨ä¸‹è½½æœ€æ–°çš„ v4/v5 æ¨¡åž‹
                    instance = PaddleOCR(
                        use_angle_cls=True,
                        use_doc_orientation_classify=True,
                        lang='ch' if lang=='auto' else lang,
                        use_gpu=self.use_gpu,
                        show_log=False,
                        ocr_version='PP-OCRv4' # v4 tag å…¼å®¹ v5
                    )
                
                self._models[cache_key] = instance
                return instance
            except Exception as e:
                logger.error(f"âŒ Load model failed: {e}")
                raise

    def parse(self, file_path: str, output_path: str, **kwargs) -> Dict[str, Any]:
        """
        ç»Ÿä¸€è§£æžå…¥å£
        """
        file_path = Path(file_path)
        output_path = Path(output_path)
        output_path.mkdir(parents=True, exist_ok=True)
        
        model_type = kwargs.get('model_type', 'paddleocr-vl')
        lang = kwargs.get('lang', 'ch')
        
        model = self._get_model(model_type, lang)
        
        markdown_content = ""
        json_data = {}

        try:
            # === åˆ†æ”¯ A: äº§çº¿ç±»æ¨¡åž‹ (PaddleOCR-VL, StructureV3, ChatOCR) ===
            # è¿™äº›æ¨¡åž‹åŽŸç”Ÿæ”¯æŒ .predict(input=path) ä¸”æ”¯æŒ PDF
            if ('paddleocr-vl' in model_type and 'vllm' not in model_type) or \
               ('pp-structure' in model_type) or \
               ('pp-chatocr' in model_type and PPChatOCRv4Doc):
                
                # 1. ChatOCR ç‰¹æ®Šå¤„ç†
                if 'pp-chatocr' in model_type and PPChatOCRv4Doc and isinstance(model, PPChatOCRv4Doc):
                    logger.info("   Running ChatOCR visual_predict...")
                    # visual_predict è¿”å›žè§†è§‰ä¿¡æ¯ï¼Œä¸è¿›è¡Œ LLM å¯¹è¯
                    res = model.visual_predict(str(file_path))
                    markdown_content = "> PP-ChatOCRv4 Visual Analysis Completed.\n> (To ask questions, configure LLM/API Key)"
                    json_data = {"visual_info": str(res)} 
                    
                # 2. VL å’Œ StructureV3 æ ‡å‡†å¤„ç†
                else:
                    logger.info(f"   Predicting with {model_type}...")
                    res = model.predict(input=str(file_path))
                    
                    # è½¬æ¢ä¸ºåˆ—è¡¨ (å¦‚æžœåªè¿”å›žå•ä¸ªç»“æžœ)
                    pages_res = list(res) if hasattr(res, '__iter__') else [res]
                    
                    # === å…³é”®ä¼˜åŒ–ï¼šä½¿ç”¨å®˜æ–¹ API è¿›è¡Œé¡µé¢é‡æž„/åˆå¹¶ ===
                    # PaddleOCR-VL 1.5 æ”¯æŒ restructure_pages
                    if 'paddleocr-vl' in model_type and hasattr(model, 'restructure_pages'):
                         try:
                             logger.info("   Restructuring pages (merging tables)...")
                             # merge_table=True åˆå¹¶è·¨é¡µè¡¨æ ¼
                             pages_res = model.restructure_pages(pages_res, merge_table=True)
                         except Exception as e:
                             logger.warning(f"Restructure pages failed: {e}")

                    # PP-StructureV3 æ”¯æŒ concatenate_markdown_pages
                    elif 'pp-structure' in model_type and hasattr(model, 'concatenate_markdown_pages'):
                        try:
                            # æå– markdown ä¿¡æ¯åˆ—è¡¨
                            md_list_struct = []
                            for p in pages_res:
                                if hasattr(p, 'markdown'):
                                    md_list_struct.append(p.markdown)
                            
                            if md_list_struct:
                                logger.info("   Concatenating markdown pages (StructureV3)...")
                                full_md = model.concatenate_markdown_pages(md_list_struct)
                                # è¦†ç›–ä¸‹é¢çš„é€é¡µæ‹¼æŽ¥é€»è¾‘
                                markdown_content = full_md
                        except Exception as e:
                            logger.warning(f"Concatenate markdown failed: {e}")

                    # === é€é¡µä¿å­˜ä¸Ž JSON æ”¶é›† (Fallback) ===
                    md_list_fallback = []
                    json_list = []
                    
                    for idx, p in enumerate(pages_res):
                        # å°è¯•ä½¿ç”¨ SDK è‡ªå¸¦ä¿å­˜æ–¹æ³•
                        if hasattr(p, 'save_to_markdown'):
                            p.save_to_markdown(str(output_path))
                        
                        # æ”¶é›†å†…å®¹
                        if hasattr(p, 'markdown'): md_list_fallback.append(p.markdown)
                        elif isinstance(p, dict) and 'markdown' in p: md_list_fallback.append(p['markdown'])
                        
                        if hasattr(p, 'json'): json_list.append(p.json)
                        elif isinstance(p, dict): json_list.append(p)
                    
                    # å¦‚æžœæ²¡æœ‰é€šè¿‡ concatenate_markdown_pages ç”Ÿæˆå†…å®¹ï¼Œåˆ™ä½¿ç”¨ fallback æ‹¼æŽ¥
                    if not markdown_content and md_list_fallback:
                        # å°è¯•è¯»å– SDK ä¿å­˜çš„æ–‡ä»¶
                        saved_md_files = sorted(list(output_path.glob("*.md")))
                        read_mds = []
                        for f in saved_md_files:
                            if f.name != "result.md": 
                                read_mds.append(f.read_text(encoding='utf-8'))
                        
                        if read_mds:
                            markdown_content = "\n\n---\n\n".join(read_mds)
                        else:
                            markdown_content = "\n\n---\n\n".join([str(m) for m in md_list_fallback])

                    json_data = {"pages": json_list}

            # === åˆ†æ”¯ B: çº¯ OCR æ¨¡åž‹ (PP-OCRv5) ===
            else:
                logger.info("   Running PP-OCRv5...")
                from PIL import Image
                imgs = []
                
                # æ‰‹åŠ¨ PDF è½¬å›¾ç‰‡
                if file_path.suffix.lower() == '.pdf':
                    doc = fitz.open(file_path)
                    for page in doc:
                        pix = page.get_pixmap(dpi=200)
                        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                        imgs.append(np.array(img))
                else:
                    imgs.append(str(file_path))

                full_md = []
                raw_res = []

                for i, img_input in enumerate(imgs):
                    res = model.ocr(img_input, cls=True)
                    page_md = f"## Page {i+1}\n"
                    
                    if res and res[0]:
                        for line in res[0]:
                            text = line[1][0]
                            page_md += text + "\n"
                    
                    full_md.append(page_md)
                    raw_res.append(str(res))
                
                markdown_content = "\n\n---\n\n".join(full_md)
                json_data = {"ocr_raw": raw_res}

            # === æœ€ç»ˆä¿å­˜ ===
            if not markdown_content: markdown_content = "(No content detected)"
            (output_path / "result.md").write_text(markdown_content, encoding="utf-8")
            
            try:
                import json
                class NpEncoder(json.JSONEncoder):
                    def default(self, obj):
                        if isinstance(obj, np.integer): return int(obj)
                        if isinstance(obj, np.floating): return float(obj)
                        if isinstance(obj, np.ndarray): return obj.tolist()
                        return super(NpEncoder, self).default(obj)
                (output_path / "result.json").write_text(json.dumps(json_data, ensure_ascii=False, indent=2, cls=NpEncoder), encoding="utf-8")
            except: pass

            return {"success": True, "markdown": markdown_content}

        except Exception as e:
            logger.error(f"Processing failed: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise

    def cleanup(self):
        try:
            import paddle, gc
            if self.use_gpu: paddle.device.cuda.empty_cache()
            gc.collect()
        except: pass

_engine = None
def get_engine() -> PaddleOCREngine:
    global _engine
    if _engine is None: _engine = PaddleOCREngine()
    return _engine
