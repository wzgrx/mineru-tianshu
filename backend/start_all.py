#!/usr/bin/env python3
"""
MinerU Tianshu - å¯åŠ¨æ‰€æœ‰æœåŠ¡

1. API Server (FastAPI) - ç«¯å£ 8000
2. LitServe Worker Pool - ç«¯å£ 8001
3. Task Scheduler (å¯é€‰) - åå°ä»»åŠ¡è°ƒåº¦
4. MCP Server (å¯é€‰) - ç«¯å£ 8002

è‡ªåŠ¨æ£€æŸ¥å¹¶ä¸‹è½½ OCR æ¨¡å‹ï¼ˆPaddleOCR-VLï¼‰
æ”¯æŒ GPU åŠ é€Ÿã€ä»»åŠ¡é˜Ÿåˆ—ã€ä¼˜å…ˆçº§ç®¡ç†
"""

import subprocess
import signal
import sys
import time
import os
from loguru import logger
from pathlib import Path
import argparse
from utils import parse_list_arg
from dotenv import load_dotenv


class TianshuLauncher:
    """å¤©æ¢æœåŠ¡å¯åŠ¨å™¨"""

    def __init__(
        self,
        output_dir="/tmp/mineru_tianshu_output",
        api_port=8000,
        worker_port=8001,
        workers_per_device=1,
        devices="auto",
        accelerator="auto",
        enable_mcp=False,
        mcp_port=8002,
        paddleocr_vl_vllm_engine_enabled=False,  # æ–°å¢paddle ocr vllm engine é…ç½®
        paddleocr_vl_vllm_api_list=[],  # æ–°å¢paddle ocr vllm engine é…ç½®
    ):
        self.output_dir = output_dir
        self.api_port = api_port
        self.worker_port = worker_port
        self.workers_per_device = workers_per_device
        self.devices = devices
        self.accelerator = accelerator
        self.enable_mcp = enable_mcp
        self.mcp_port = mcp_port
        self.processes = []
        self.paddleocr_vl_vllm_engine_enabled = paddleocr_vl_vllm_engine_enabled
        self.paddleocr_vl_vllm_api_list = paddleocr_vl_vllm_api_list

    def check_ocr_models(self):
        """æ£€æŸ¥å¹¶ä¸‹è½½æ‰€æœ‰ OCR æ¨¡å‹ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡å¯åŠ¨ï¼‰"""
        import threading

        # 1. æ£€æŸ¥ PaddleOCR-VL æ¨¡å‹
        def check_paddleocr_vl():
            try:
                from paddleocr_vl import PaddleOCRVLEngine

                logger.info("ğŸ” Checking PaddleOCR-VL...")
                logger.info("   Note: PaddleOCR-VL models are auto-managed by PaddleOCR")
                logger.info("   Cache location: ~/.paddleocr/models/")
                logger.info("   Model will be auto-downloaded on first use (~2GB)")

                # æ£€æŸ¥ home ç›®å½•çš„æ¨¡å‹ç¼“å­˜
                home_dir = Path.home()
                model_cache_dir = home_dir / ".paddleocr" / "models"

                if model_cache_dir.exists():
                    logger.info(f"âœ… PaddleOCR model cache found at: {model_cache_dir}")
                else:
                    logger.info("â„¹ï¸  PaddleOCR model cache not found, will be created on first use")

                # ç®€å•åˆå§‹åŒ–å¼•æ“ï¼ˆä¸è§¦å‘ä¸‹è½½ï¼‰
                try:
                    PaddleOCRVLEngine()
                    logger.info("âœ… PaddleOCR-VL engine initialized successfully")
                except Exception as e:
                    logger.warning(f"âš ï¸  PaddleOCR-VL initialization failed: {e}")
                    logger.info("   This is normal if GPU is not available or dependencies are missing")

            except ImportError:
                logger.debug("PaddleOCR-VL not installed, skipping check")
            except Exception as e:
                logger.debug(f"PaddleOCR-VL check skipped: {e}")

        # åœ¨åå°çº¿ç¨‹ä¸­ä¸‹è½½æ¨¡å‹
        thread_paddleocr = threading.Thread(target=check_paddleocr_vl, daemon=True)
        thread_paddleocr.start()

    def start_services(self):
        """å¯åŠ¨æ‰€æœ‰æœåŠ¡"""
        logger.info("=" * 70)
        logger.info("ğŸš€ MinerU Tianshu - AI Data Preprocessing Platform")
        logger.info("=" * 70)
        logger.info("å¤©æ¢ - ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å°")
        logger.info("æ”¯æŒæ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç†")
        logger.info("")

        try:
            total_services = 4 if self.enable_mcp else 3

            # 1. å¯åŠ¨ API Server
            logger.info(f"ğŸ“¡ [1/{total_services}] Starting API Server...")
            env = os.environ.copy()
            env["API_PORT"] = str(self.api_port)
            env["OUTPUT_PATH"] = self.output_dir  # è®¾ç½®è¾“å‡ºç›®å½•ï¼ˆä¸ Worker ä¿æŒä¸€è‡´ï¼‰
            api_proc = subprocess.Popen([sys.executable, "api_server.py"], cwd=Path(__file__).parent, env=env)
            self.processes.append(("API Server", api_proc))
            time.sleep(3)

            if api_proc.poll() is not None:
                logger.error("âŒ API Server failed to start!")
                return False

            logger.info(f"   âœ… API Server started (PID: {api_proc.pid})")
            logger.info(f"   ğŸ“– API Docs: http://localhost:{self.api_port}/docs")
            logger.info("")

            # 2. å¯åŠ¨ LitServe Worker Pool
            logger.info(f"âš™ï¸  [2/{total_services}] Starting LitServe Worker Pool...")
            worker_env = os.environ.copy()
            worker_env["WORKER_PORT"] = str(self.worker_port)
            worker_env["OUTPUT_PATH"] = self.output_dir

            worker_cmd = [
                sys.executable,
                "litserve_worker.py",
                "--output-dir",
                self.output_dir,
                "--accelerator",
                self.accelerator,
                "--workers-per-device",
                str(self.workers_per_device),
                "--port",
                str(self.worker_port),
                "--devices",
                str(self.devices) if isinstance(self.devices, str) else ",".join(map(str, self.devices)),
            ]

            # åªåœ¨å¯ç”¨æ—¶æ‰æ·»åŠ  paddleocr-vl-vllm-engine-enabled å‚æ•°
            if self.paddleocr_vl_vllm_engine_enabled:
                worker_cmd.extend(["--paddleocr-vl-vllm-engine-enabled"])
            # æ·»åŠ  paddleocr-vl-vllm-api-list å‚æ•°
            worker_cmd.extend(["--paddleocr-vl-vllm-api-list", str(self.paddleocr_vl_vllm_api_list)])

            worker_proc = subprocess.Popen(worker_cmd, cwd=Path(__file__).parent, env=worker_env)
            self.processes.append(("LitServe Workers", worker_proc))
            time.sleep(5)

            if worker_proc.poll() is not None:
                logger.error("âŒ LitServe Workers failed to start!")
                return False

            logger.info(f"   âœ… LitServe Workers started (PID: {worker_proc.pid})")
            logger.info(f"   ğŸ”Œ Worker Port: {self.worker_port}")
            logger.info(f"   ğŸ‘· Workers per Device: {self.workers_per_device}")
            logger.info("")

            # 3. å¯åŠ¨ Task Scheduler
            logger.info(f"ğŸ”„ [3/{total_services}] Starting Task Scheduler...")
            scheduler_cmd = [
                sys.executable,
                "task_scheduler.py",
                "--litserve-url",
                f"http://localhost:{self.worker_port}/predict",
                "--wait-for-workers",
            ]

            scheduler_proc = subprocess.Popen(scheduler_cmd, cwd=Path(__file__).parent)
            self.processes.append(("Task Scheduler", scheduler_proc))
            time.sleep(3)

            if scheduler_proc.poll() is not None:
                logger.error("âŒ Task Scheduler failed to start!")
                return False

            logger.info(f"   âœ… Task Scheduler started (PID: {scheduler_proc.pid})")
            logger.info("")

            # 4. å¯åŠ¨ MCP Serverï¼ˆå¯é€‰ï¼‰
            if self.enable_mcp:
                logger.info(f"ğŸ”Œ [4/{total_services}] Starting MCP Server...")
                mcp_env = os.environ.copy()
                mcp_env["API_BASE_URL"] = f"http://localhost:{self.api_port}"
                mcp_env["MCP_PORT"] = str(self.mcp_port)
                mcp_env["MCP_HOST"] = "0.0.0.0"

                mcp_proc = subprocess.Popen([sys.executable, "mcp_server.py"], cwd=Path(__file__).parent, env=mcp_env)
                self.processes.append(("MCP Server", mcp_proc))
                time.sleep(3)

                if mcp_proc.poll() is not None:
                    logger.error("âŒ MCP Server failed to start!")
                    return False

                logger.info(f"   âœ… MCP Server started (PID: {mcp_proc.pid})")
                logger.info(f"   ğŸŒ MCP Endpoint: http://localhost:{self.mcp_port}/mcp")
                logger.info("")

            # å¯åŠ¨æˆåŠŸ
            logger.info("=" * 70)
            logger.info("âœ… All Services Started Successfully!")
            logger.info("=" * 70)
            logger.info("")
            logger.info("ğŸ“š Quick Start:")
            logger.info(f"   â€¢ API Documentation: http://localhost:{self.api_port}/docs")
            logger.info(f"   â€¢ Submit Task:       POST http://localhost:{self.api_port}/api/v1/tasks/submit")
            logger.info(f"   â€¢ Query Status:      GET  http://localhost:{self.api_port}/api/v1/tasks/{{task_id}}")
            logger.info(f"   â€¢ Queue Stats:       GET  http://localhost:{self.api_port}/api/v1/queue/stats")
            if self.enable_mcp:
                logger.info(f"   â€¢ MCP Endpoint:      http://localhost:{self.mcp_port}/mcp/sse")
            logger.info("")
            logger.info("ğŸ”§ Service Details:")
            for name, proc in self.processes:
                logger.info(f"   â€¢ {name:20s} PID: {proc.pid}")
            logger.info("")
            logger.info("âš ï¸  Press Ctrl+C to stop all services")
            logger.info("=" * 70)
            logger.info("")
            logger.info("ğŸ’– If you find this project helpful, please consider:")
            logger.info("   â­ Star us on GitHub: https://github.com/magicyuan876/mineru-tianshu")
            logger.info("   ğŸ› Report issues or contribute: https://github.com/magicyuan876/mineru-tianshu/issues")
            logger.info("")
            logger.info("=" * 70)
            logger.info("")

            # æ‰€æœ‰æœåŠ¡å¯åŠ¨å®Œæˆåï¼Œæ£€æŸ¥å¹¶ä¸‹è½½æ‰€æœ‰ OCR æ¨¡å‹
            self.check_ocr_models()

            return True

        except Exception as e:
            logger.error(f"âŒ Failed to start services: {e}")
            self.stop_services()
            return False

    def stop_services(self, signum=None, frame=None):
        """åœæ­¢æ‰€æœ‰æœåŠ¡"""
        logger.info("")
        logger.info("=" * 70)
        logger.info("â¹ï¸  Stopping All Services...")
        logger.info("=" * 70)

        for name, proc in self.processes:
            if proc.poll() is None:  # è¿›ç¨‹ä»åœ¨è¿è¡Œ
                logger.info(f"   Stopping {name} (PID: {proc.pid})...")
                proc.terminate()

        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹ç»“æŸ
        for name, proc in self.processes:
            try:
                proc.wait(timeout=10)
                logger.info(f"   âœ… {name} stopped")
            except subprocess.TimeoutExpired:
                logger.warning(f"   âš ï¸  {name} did not stop gracefully, forcing...")
                proc.kill()
                proc.wait()

        logger.info("=" * 70)
        logger.info("âœ… All Services Stopped")
        logger.info("=" * 70)
        sys.exit(0)

    def wait(self):
        """ç­‰å¾…æ‰€æœ‰æœåŠ¡"""
        try:
            while True:
                time.sleep(1)

                # æ£€æŸ¥è¿›ç¨‹çŠ¶æ€
                for name, proc in self.processes:
                    if proc.poll() is not None:
                        logger.error(f"âŒ {name} unexpectedly stopped!")
                        self.stop_services()
                        return

        except KeyboardInterrupt:
            self.stop_services()


def main():
    """ä¸»å‡½æ•°"""
    env_path = Path(__file__).parent / ".env"
    if env_path.exists():
        load_dotenv(dotenv_path=env_path)
        logger.info(f"âœ… Loaded .env from: {env_path}")
    else:
        logger.error(f"âŒ .env file not found at: {env_path}")
        logger.error("Please create a .env file in the backend directory with required environment variables")
        sys.exit(1)
    parser = argparse.ArgumentParser(
        description="MinerU Tianshu - ç»Ÿä¸€å¯åŠ¨è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ä½¿ç”¨é»˜è®¤é…ç½®å¯åŠ¨ï¼ˆè‡ªåŠ¨æ£€æµ‹GPUï¼‰
  python start_all.py

  # ä½¿ç”¨CPUæ¨¡å¼
  python start_all.py --accelerator cpu

  # æŒ‡å®šè¾“å‡ºç›®å½•å’Œç«¯å£
  python start_all.py --output-dir /data/output --api-port 8080

  # æ¯ä¸ªGPUå¯åŠ¨2ä¸ªworker
  python start_all.py --accelerator cuda --workers-per-device 2

  # åªä½¿ç”¨æŒ‡å®šçš„GPU
  python start_all.py --accelerator cuda --devices 0,1

  # å¯ç”¨ MCP Server æ”¯æŒï¼ˆç”¨äº AI åŠ©æ‰‹è°ƒç”¨ï¼‰
  python start_all.py --enable-mcp --mcp-port 8002
        """,
    )

    parser.add_argument(
        "--output-dir",
        type=str,
        default="/tmp/mineru_tianshu_output",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: /tmp/mineru_tianshu_output)",
    )
    parser.add_argument("--api-port", type=int, default=8000, help="APIæœåŠ¡å™¨ç«¯å£ (é»˜è®¤: 8000)")
    parser.add_argument("--worker-port", type=int, default=8001, help="WorkeræœåŠ¡å™¨ç«¯å£ (é»˜è®¤: 8001)")
    parser.add_argument(
        "--accelerator",
        type=str,
        default="auto",
        choices=["auto", "cuda", "cpu"],
        help="åŠ é€Ÿå™¨ç±»å‹ (é»˜è®¤: autoï¼Œè‡ªåŠ¨æ£€æµ‹)",
    )
    parser.add_argument("--workers-per-device", type=int, default=1, help="æ¯ä¸ªGPUçš„workeræ•°é‡ (é»˜è®¤: 1)")
    parser.add_argument("--devices", type=str, default="auto", help="ä½¿ç”¨çš„GPUè®¾å¤‡ï¼Œé€—å·åˆ†éš” (é»˜è®¤: autoï¼Œä½¿ç”¨æ‰€æœ‰GPU)")
    parser.add_argument(
        "--enable-mcp", action="store_true", help="å¯ç”¨ MCP Serverï¼ˆæ”¯æŒ Model Context Protocol è¿œç¨‹è°ƒç”¨ï¼‰"
    )
    parser.add_argument("--mcp-port", type=int, default=8002, help="MCP Server ç«¯å£ (é»˜è®¤: 8002)")
    # é…ç½® paddleocr-vl-vllm engine
    parser.add_argument(
        "--paddleocr-vl-vllm-engine-enabled",
        action="store_true",
        default=False,
        help="æ˜¯å¦å¯ç”¨ PaddleOCR VL VLLM å¼•æ“ (é»˜è®¤: False)",
    )
    parser.add_argument(
        "--paddleocr-vl-vllm-api-list",
        type=parse_list_arg,
        default=[],
        help='PaddleOCR VL VLLM API åˆ—è¡¨ï¼ˆPython list å­—é¢é‡æ ¼å¼ï¼Œå¦‚: \'["http://0.0.0.0:17300/v1", "http://0.0.0.0:17301/v1"]\'ï¼‰',
    )

    args = parser.parse_args()

    # å¤„ç† devices å‚æ•°
    devices = args.devices
    if devices != "auto":
        try:
            devices = [int(d) for d in devices.split(",")]
        except ValueError:
            logger.warning(f"Invalid devices format: {devices}, using 'auto'")
            devices = "auto"
    if args.paddleocr_vl_vllm_engine_enabled:
        logger.success("start_all è„šæœ¬ä¸­ PaddleOCR VL VLLM å¼•æ“å·²è®¾ç½®å¯ç”¨")
        if not args.paddleocr_vl_vllm_api_list:
            logger.error(
                "è¯·é…ç½® --paddleocr-vl-vllm-api-list å‚æ•°, æˆ–è€…ç§»é™¤ --paddleocr-vl-vllm-engine-enabled æ¥å…³é—­ PaddleOCR VL VLLM å¼•æ“"
            )
            sys.exit(1)
        else:
            logger.success(f"PaddleOCR VL VLLM å¼•æ“ï¼ŒAPI åˆ—è¡¨ä¸º: {args.paddleocr_vl_vllm_api_list}")
    else:
        logger.info("start_all è„šæœ¬ä¸­PaddleOCR VL VLLM å¼•æ“å·²è®¾ç½®ä¸å¯ç”¨")
    # åˆ›å»ºå¯åŠ¨å™¨
    launcher = TianshuLauncher(
        output_dir=args.output_dir,
        api_port=args.api_port,
        worker_port=args.worker_port,
        workers_per_device=args.workers_per_device,
        devices=devices,
        accelerator=args.accelerator,
        enable_mcp=args.enable_mcp,
        mcp_port=args.mcp_port,
        paddleocr_vl_vllm_engine_enabled=args.paddleocr_vl_vllm_engine_enabled,
        paddleocr_vl_vllm_api_list=args.paddleocr_vl_vllm_api_list,
    )

    # è®¾ç½®ä¿¡å·å¤„ç†
    signal.signal(signal.SIGINT, launcher.stop_services)
    signal.signal(signal.SIGTERM, launcher.stop_services)

    # å¯åŠ¨æœåŠ¡
    if launcher.start_services():
        launcher.wait()
    else:
        sys.exit(1)


if __name__ == "__main__":
    main()
